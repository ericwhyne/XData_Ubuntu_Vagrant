.input.start
2013-10-10 13:25:35,088 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-10-10 13:25:35,091 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-10-10 13:25:35,092 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-10-10 13:25:35,093 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-10-10 13:25:35,094 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - map.input.length is deprecated. Instead, use mapreduce.map.input.length
2013-10-10 13:25:35,104 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-10-10 13:25:35,106 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
2013-10-10 13:25:35,108 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - map.input.file is deprecated. Instead, use mapreduce.map.input.file
2013-10-10 13:25:35,114 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-10-10 13:25:35,852 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1288)) - Job job_local880575836_0001 running in uber mode : false
2013-10-10 13:25:35,852 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1295)) -  map 0% reduce 0%
2013-10-10 13:25:40,949 INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(500)) - hdfs://xd-namenode.xdata.data-tactics-corp.com:8020/temp/akamai_raw/20121112_traces.tar.txt._COPYING_:0+17816576 > map
2013-10-10 13:26:35,190 WARN  hdfs.DFSClient (DFSInputStream.java:blockSeekTo(505)) - Failed to connect to /10.1.92.123:50010 for block, add to deadNodes and continue. org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.123:50010]
org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.123:50010]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:528)
	at org.apache.hadoop.hdfs.DFSInputStream.newTcpPeer(DFSInputStream.java:863)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:1011)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:196)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:182)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
2013-10-10 13:27:35,221 WARN  hdfs.DFSClient (DFSInputStream.java:blockSeekTo(505)) - Failed to connect to /10.1.92.113:50010 for block, add to deadNodes and continue. org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.113:50010]
org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.113:50010]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:528)
	at org.apache.hadoop.hdfs.DFSInputStream.newTcpPeer(DFSInputStream.java:863)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:1011)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:196)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:182)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
2013-10-10 13:28:35,282 WARN  hdfs.DFSClient (DFSInputStream.java:blockSeekTo(505)) - Failed to connect to /10.1.92.127:50010 for block, add to deadNodes and continue. org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.127:50010]
org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.127:50010]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:528)
	at org.apache.hadoop.hdfs.DFSInputStream.newTcpPeer(DFSInputStream.java:863)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:1011)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:196)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:182)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
2013-10-10 13:28:35,283 INFO  hdfs.DFSClient (DFSInputStream.java:chooseDataNode(758)) - Could not obtain BP-704024581-10.1.92.51-1351611952396:blk_-3282371606459355225_13253257 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-10-10 13:28:35,283 WARN  hdfs.DFSClient (DFSInputStream.java:chooseDataNode(773)) - DFS chooseDataNode: got # 1 IOException, will wait for 2815.3388573707825 msec.
2013-10-10 13:29:38,173 WARN  hdfs.DFSClient (DFSInputStream.java:blockSeekTo(505)) - Failed to connect to /10.1.92.123:50010 for block, add to deadNodes and continue. org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.123:50010]
org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.123:50010]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:528)
	at org.apache.hadoop.hdfs.DFSInputStream.newTcpPeer(DFSInputStream.java:863)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:1011)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:196)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:182)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
^C2013-10-10 13:30:00,277 INFO  streaming.PipeMapRed (PipeMapRed.java:run(460)) - MRErrorThread done
hdfs@glamdring-xps12:~/workspace/hadoop/scripts$ ifconfig
lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          inet6 addr: ::1/128 Scope:Host
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:5668 errors:0 dropped:0 overruns:0 frame:0
          TX packets:5668 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:523549 (523.5 KB)  TX bytes:523549 (523.5 KB)

wlan0     Link encap:Ethernet  HWaddr c8:f7:33:e4:c0:b9  
          inet addr:172.16.98.252  Bcast:172.16.98.255  Mask:255.255.255.0
          inet6 addr: fe80::caf7:33ff:fee4:c0b9/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:50294 errors:0 dropped:1 overruns:0 frame:0
          TX packets:39065 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:30412376 (30.4 MB)  TX bytes:10493673 (10.4 MB)

hdfs@glamdring-xps12:~/workspace/hadoop/scripts$ ./compute-streaming-test 
2013-10-10 13:31:19,347 WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-10-10 13:31:20,380 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - session.id is deprecated. Instead, use dfs.metrics.session-id
2013-10-10 13:31:20,381 INFO  jvm.JvmMetrics (JvmMetrics.java:init(76)) - Initializing JVM Metrics with processName=JobTracker, sessionId=
2013-10-10 13:31:20,407 INFO  jvm.JvmMetrics (JvmMetrics.java:init(71)) - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2013-10-10 13:31:21,539 ERROR security.UserGroupInformation (UserGroupInformation.java:doAs(1411)) - PriviledgedActionException as:hdfs (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://xd-namenode.xdata.data-tactics-corp.com:8020/temp/akwc already exists
2013-10-10 13:31:21,539 ERROR security.UserGroupInformation (UserGroupInformation.java:doAs(1411)) - PriviledgedActionException as:hdfs (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://xd-namenode.xdata.data-tactics-corp.com:8020/temp/akwc already exists
2013-10-10 13:31:21,539 ERROR streaming.StreamJob (StreamJob.java:submitAndMonitorJob(1028)) - Error Launching job : Output directory hdfs://xd-namenode.xdata.data-tactics-corp.com:8020/temp/akwc already exists
Streaming Command Failed!
hdfs@glamdring-xps12:~/workspace/hadoop/scripts$ ./compute-hdfs -rmdir /temp/akwc
13/10/10 13:31:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
rmdir: `/temp/akwc': Directory is not empty
hdfs@glamdring-xps12:~/workspace/hadoop/scripts$ ./compute-hdfs -ls /temp/akwc
13/10/10 13:31:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 1 items
drwxr-xr-x   - hdfs hadoop          0 2013-10-10 13:25 /temp/akwc/_temporary
hdfs@glamdring-xps12:~/workspace/hadoop/scripts$ ./compute-hdfs -rmr /temp/akwc
rmr: DEPRECATED: Please use 'rm -r' instead.
13/10/10 13:32:10 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Deleted /temp/akwc
hdfs@glamdring-xps12:~/workspace/hadoop/scripts$ ./compute-hdfs -rm -r /temp/akwc
13/10/10 13:32:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
rm: `/temp/akwc': No such file or directory
hdfs@glamdring-xps12:~/workspace/hadoop/scripts$ ./compute-streaming-test 
2013-10-10 13:33:11,511 WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-10-10 13:33:12,321 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - session.id is deprecated. Instead, use dfs.metrics.session-id
2013-10-10 13:33:12,322 INFO  jvm.JvmMetrics (JvmMetrics.java:init(76)) - Initializing JVM Metrics with processName=JobTracker, sessionId=
2013-10-10 13:33:12,347 INFO  jvm.JvmMetrics (JvmMetrics.java:init(71)) - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2013-10-10 13:33:12,579 INFO  mapred.FileInputFormat (FileInputFormat.java:listStatus(233)) - Total input paths to process : 1
2013-10-10 13:33:12,673 INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(368)) - number of splits:1
2013-10-10 13:33:12,692 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.jar is deprecated. Instead, use mapreduce.job.jar
2013-10-10 13:33:12,693 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2013-10-10 13:33:12,694 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.mapoutput.value.class is deprecated. Instead, use mapreduce.map.output.value.class
2013-10-10 13:33:12,695 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.job.name is deprecated. Instead, use mapreduce.job.name
2013-10-10 13:33:12,695 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
2013-10-10 13:33:12,695 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2013-10-10 13:33:12,695 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-10-10 13:33:12,696 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2013-10-10 13:33:12,696 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.mapoutput.key.class is deprecated. Instead, use mapreduce.map.output.key.class
2013-10-10 13:33:12,697 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2013-10-10 13:33:12,862 INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(438)) - Submitting tokens for job: job_local421243016_0001
2013-10-10 13:33:13,147 INFO  mapreduce.Job (Job.java:submit(1222)) - The url to track the job: http://localhost:8080/
2013-10-10 13:33:13,153 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1267)) - Running job: job_local421243016_0001
2013-10-10 13:33:13,153 INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(319)) - OutputCommitter set in config null
2013-10-10 13:33:13,159 INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(337)) - OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2013-10-10 13:33:13,209 INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(385)) - Waiting for map tasks
2013-10-10 13:33:13,213 INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(212)) - Starting task: attempt_local421243016_0001_m_000000_0
2013-10-10 13:33:13,309 INFO  mapred.Task (Task.java:initialize(566)) -  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@74bfed5a
2013-10-10 13:33:13,319 INFO  mapred.MapTask (MapTask.java:updateJobWithSplit(455)) - Processing split: hdfs://xd-namenode.xdata.data-tactics-corp.com:8020/temp/akamai_raw/20121112_traces.tar.txt._COPYING_:0+17816576
2013-10-10 13:33:13,351 INFO  mapred.MapTask (MapTask.java:runOldMapper(414)) - numReduceTasks: 1
2013-10-10 13:33:13,361 INFO  mapred.MapTask (MapTask.java:createSortingCollector(386)) - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2013-10-10 13:33:13,433 INFO  mapred.MapTask (MapTask.java:setEquator(1168)) - (EQUATOR) 0 kvi 26214396(104857584)
2013-10-10 13:33:13,434 INFO  mapred.MapTask (MapTask.java:init(960)) - mapreduce.task.io.sort.mb: 100
2013-10-10 13:33:13,434 INFO  mapred.MapTask (MapTask.java:init(961)) - soft limit at 83886080
2013-10-10 13:33:13,434 INFO  mapred.MapTask (MapTask.java:init(962)) - bufstart = 0; bufvoid = 104857600
2013-10-10 13:33:13,434 INFO  mapred.MapTask (MapTask.java:init(963)) - kvstart = 26214396; length = 6553600
2013-10-10 13:33:13,444 INFO  streaming.PipeMapRed (PipeMapRed.java:configure(199)) - PipeMapRed exec [/bin/cat]
2013-10-10 13:33:13,446 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-10-10 13:33:13,446 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - user.name is deprecated. Instead, use mapreduce.job.user.name
2013-10-10 13:33:13,447 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - map.input.start is deprecated. Instead, use mapreduce.map.input.start
2013-10-10 13:33:13,447 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-10-10 13:33:13,450 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-10-10 13:33:13,451 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-10-10 13:33:13,453 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-10-10 13:33:13,454 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - map.input.length is deprecated. Instead, use mapreduce.map.input.length
2013-10-10 13:33:13,457 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-10-10 13:33:13,460 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir
2013-10-10 13:33:13,462 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - map.input.file is deprecated. Instead, use mapreduce.map.input.file
2013-10-10 13:33:13,463 WARN  conf.Configuration (Configuration.java:warnOnceIfDeprecated(824)) - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-10-10 13:33:14,157 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1288)) - Job job_local421243016_0001 running in uber mode : false
2013-10-10 13:33:14,157 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1295)) -  map 0% reduce 0%
2013-10-10 13:33:19,292 INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(500)) - hdfs://xd-namenode.xdata.data-tactics-corp.com:8020/temp/akamai_raw/20121112_traces.tar.txt._COPYING_:0+17816576 > map
2013-10-10 13:34:13,566 WARN  hdfs.DFSClient (DFSInputStream.java:blockSeekTo(505)) - Failed to connect to /10.1.92.113:50010 for block, add to deadNodes and continue. org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.113:50010]
org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.113:50010]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:528)
	at org.apache.hadoop.hdfs.DFSInputStream.newTcpPeer(DFSInputStream.java:863)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:1011)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:196)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:182)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
2013-10-10 13:35:13,578 WARN  hdfs.DFSClient (DFSInputStream.java:blockSeekTo(505)) - Failed to connect to /10.1.92.123:50010 for block, add to deadNodes and continue. org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.123:50010]
org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.123:50010]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:528)
	at org.apache.hadoop.hdfs.DFSInputStream.newTcpPeer(DFSInputStream.java:863)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:1011)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:196)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:182)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
2013-10-10 13:36:13,640 WARN  hdfs.DFSClient (DFSInputStream.java:blockSeekTo(505)) - Failed to connect to /10.1.92.127:50010 for block, add to deadNodes and continue. org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.127:50010]
org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.127:50010]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:528)
	at org.apache.hadoop.hdfs.DFSInputStream.newTcpPeer(DFSInputStream.java:863)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:1011)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:196)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:182)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
2013-10-10 13:36:13,642 INFO  hdfs.DFSClient (DFSInputStream.java:chooseDataNode(758)) - Could not obtain BP-704024581-10.1.92.51-1351611952396:blk_-3282371606459355225_13253257 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-10-10 13:36:13,642 WARN  hdfs.DFSClient (DFSInputStream.java:chooseDataNode(773)) - DFS chooseDataNode: got # 1 IOException, will wait for 2392.468769299221 msec.
2013-10-10 13:37:16,074 WARN  hdfs.DFSClient (DFSInputStream.java:blockSeekTo(505)) - Failed to connect to /10.1.92.127:50010 for block, add to deadNodes and continue. org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.127:50010]
org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.127:50010]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:528)
	at org.apache.hadoop.hdfs.DFSInputStream.newTcpPeer(DFSInputStream.java:863)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:1011)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:196)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:182)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
2013-10-10 13:38:16,135 WARN  hdfs.DFSClient (DFSInputStream.java:blockSeekTo(505)) - Failed to connect to /10.1.92.123:50010 for block, add to deadNodes and continue. org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.123:50010]
org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.123:50010]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:528)
	at org.apache.hadoop.hdfs.DFSInputStream.newTcpPeer(DFSInputStream.java:863)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:1011)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:196)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:182)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
2013-10-10 13:39:16,154 WARN  hdfs.DFSClient (DFSInputStream.java:blockSeekTo(505)) - Failed to connect to /10.1.92.113:50010 for block, add to deadNodes and continue. org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.113:50010]
org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.113:50010]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:528)
	at org.apache.hadoop.hdfs.DFSInputStream.newTcpPeer(DFSInputStream.java:863)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:1011)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:196)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:182)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
2013-10-10 13:39:16,155 INFO  hdfs.DFSClient (DFSInputStream.java:chooseDataNode(758)) - Could not obtain BP-704024581-10.1.92.51-1351611952396:blk_-3282371606459355225_13253257 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-10-10 13:39:16,155 WARN  hdfs.DFSClient (DFSInputStream.java:chooseDataNode(773)) - DFS chooseDataNode: got # 2 IOException, will wait for 4444.389857135439 msec.
2013-10-10 13:40:20,664 WARN  hdfs.DFSClient (DFSInputStream.java:blockSeekTo(505)) - Failed to connect to /10.1.92.113:50010 for block, add to deadNodes and continue. org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.113:50010]
org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.113:50010]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:528)
	at org.apache.hadoop.hdfs.DFSInputStream.newTcpPeer(DFSInputStream.java:863)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:1011)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:196)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:182)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
^A^A2013-10-10 13:41:20,715 WARN  hdfs.DFSClient (DFSInputStream.java:blockSeekTo(505)) - Failed to connect to /10.1.92.123:50010 for block, add to deadNodes and continue. org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.123:50010]
org.apache.hadoop.net.ConnectTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=/10.1.92.123:50010]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:528)
	at org.apache.hadoop.hdfs.DFSInputStream.newTcpPeer(DFSInputStream.java:863)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:1011)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:471)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:662)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:706)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:206)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:196)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:182)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:428)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
hardcopy -h output.txt


